{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import matplotlib.image as mpimg\n", "import argparse\n", "import math\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import torch.multiprocessing as mp\n", "import numpy as np\n", "import torchvision\n", "from torch.utils import data\n", "from torchvision import datasets, models, transforms\n", "from sklearn.model_selection import StratifiedKFold\n", "import matplotlib.pyplot as plt\n", "import PIL\n", "from PIL import Image\n", "import time\n", "import random\n", "from parseData import parseData\n", "from efficientnet_pytorch import EfficientNet\n", "from visualize_model import visualize_model\n", "from run_model import run_model\n", "from CustomDataset import CustomDataset\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Here every type on argument that the user can send in is declared. Configurations ranging from hyperparamters in the model to location of outputfiles. <br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = argparse.ArgumentParser(description='PyTorch EfficientNet Training')\n", "parser.add_argument('--data', metavar='DIR', default=\"KI-dataset-4-types/All_Slices/\",\n", "                    help='path to KI-Dataset folder')\n", "parser.add_argument('-a', '--arch', metavar='ARCH', default='efficientnet-b0',\n", "                    help='model architecture (default: efficientnet-b0)')\n", "parser.add_argument('-j', '--workers', default=1, type=int, metavar='N',\n", "                    help='number of data loading workers (default: 1)')\n", "parser.add_argument('--epochs', default=15, type=int, metavar='N',\n", "                    help='number of total epochs to run')\n", "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n", "                    help='manual epoch number (useful on restarts)')\n", "parser.add_argument('-b', '--batch-size', default=8, type=int,\n", "                    metavar='N',\n", "                    help='mini-batch size (default:8), this is the total '\n", "                         'batch size of all GPUs on the current node when '\n", "                         'using Data Parallel or Distributed Data Parallel')\n", "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n", "                    metavar='LR', help='initial learning rate', dest='lr')\n", "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n", "                    help='momentum')\n", "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n", "                    metavar='W', help='weight decay (default: 1e-4)',\n", "                    dest='weight_decay')\n", "parser.add_argument('-p', '--print-freq', default=10, type=int,\n", "                    metavar='N', help='print frequency (default: 10)')\n", "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n", "                    help='path to latest checkpoint (default: none)')\n", "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n", "                    help='evaluate model on test set')\n", "parser.add_argument('-val', '--validate', dest='validate', action='store_true',\n", "                    help='evaluate model on validation set')\n", "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n", "                    help='use pre-trained model')\n", "parser.add_argument('--feature_extract', dest='feature_extract',\n", "                    action='store_true',\n", "                    help=\"Train only last layer (otherwise full model)\")\n", "parser.add_argument('--seed', default=None, type=int,\n", "                    help='seed for initializing training. ')\n", "parser.add_argument('--gpu', default=None, type=int,\n", "                    help='GPU id to use.')\n", "parser.add_argument('--image_size', default=32, type=int,\n", "                    help='image size')\n", "parser.add_argument('--advprop', default=False, action='store_true',\n", "                    help='use advprop or not')\n", "parser.add_argument('--upsample', default=True, action='store_true',\n", "                    help='upsample, else use class weights')\n", "parser.add_argument('--filter', default=\"\",\n", "                    help='filter we want to use for training the model')\n", "parser.add_argument('--outdest', default=\"\",\n", "                    help='where we want to save our output data')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Here we define the amount of cell classes and the files to be used in the training and testing dataset.<br>\n", "We also define the amount of number k-fold validation.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_classes = 4\n", "class_names = ['inflammatory', 'lymphocyte', 'fibroblast and endothelial',\n", "               'epithelial', 'apoptosis / civiatte body'] #'apoptosis / civiatte body' is not used throughout the project\n", "shuffle = True\n", "k = 5 # Cross-validation splits\n", "train_label_paths = [\n", "    \"P19_1_1\",\n", "    \"P19_1_2\",\n", "    \"P19_2_1\",\n", "    \"P19_2_2\",\n", "    \"P19_3_1\",\n", "    \"P19_3_2\",\n", "    \"P20_1_3\",\n", "    \"P20_1_4\",\n", "    \"P20_2_2\",\n", "    \"P20_2_3\",\n", "    \"P20_2_4\",\n", "    \"P20_3_1\",\n", "    \"P20_3_2\",\n", "    \"P20_3_3\",\n", "    \"P20_4_1\",\n", "    \"P20_4_2\",\n", "    \"P20_4_3\",\n", "    \"P20_5_1\",\n", "    \"P20_5_2\",\n", "    \"P20_6_1\",\n", "    \"P20_6_2\",\n", "    \"P20_7_1\",\n", "    \"P20_7_2\",\n", "    \"P20_8_1\",\n", "    \"P20_8_2\",\n", "    \"P20_9_1\",\n", "    \"P20_9_2\",\n", "    \"P9_1_1\",\n", "    \"P9_2_1\",\n", "    \"P9_2_2\",\n", "    \"P9_3_1\",\n", "    \"P9_3_2\",\n", "    \"P9_4_1\",\n", "    \"P9_4_2\"\n", "]\n", "test_label_paths = [\n", "    \"N10_1_1\",\n", "    \"N10_1_2\",\n", "    \"N10_1_3\",\n", "    \"N10_2_1\",\n", "    \"N10_2_2\",\n", "    \"P13_1_1\",\n", "    \"P13_1_2\",\n", "    \"P13_2_1\",\n", "    \"P13_2_2\",\n", "    \"P28_7_5\",\n", "    \"P28_8_5\",\n", "    \"P28_10_4\",\n", "    \"P28_10_5\",\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Class: AddGausianNoise<br>\n", "Function: Adds Gaussian noise to reduce overfitting<br>\n", "Input to constructor: mean and standard deviation<br>\n", "Input to call: tensor we want to add gausian noise to<br>\n", "Output of call: tensor with added gaussian noise<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AddGaussianNoise(object):\n", "    def __init__(self, mean=0., std=1.):\n", "        self.std = std\n", "        self.mean = mean\n", "    def __call__(self, tensor):\n", "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n", "    def __repr__(self):\n", "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    # gets arguments\n", "    args = parser.parse_args()\n", "    # prints cuda version and device\n", "    print(torch.version.cuda)\n", "    print(torch.cuda.FloatTensor([1.]))\n\n", "    # prints image size and type of filter\n", "    image_size = args.image_size\n", "    print('Using image size: ', image_size)\n", "    print('Using filter: ', args.filter)\n\n", "    # Define the transforms to be applied to the train and validation set\n", "    # Training set has data augmentation transforms while validation set does not\n", "    train_tsfm = transforms.Compose([\n", "        transforms.ToPILImage(),\n", "        transforms.Resize(image_size+math.floor(0.1*image_size), interpolation=PIL.Image.BICUBIC), # increases size by 1%, new pixels are interpolated (estimated) bicubicly\n", "        transforms.RandomResizedCrop(image_size), # takes a random crop from the new larger image\n", "        #transforms.RandomHorizontalFlip(),\n", "        #transforms.RandomVerticalFlip(),\n", "        transforms.ToTensor(),\n", "        AddGaussianNoise(0., 0.1) # adds Gaussian noise\n", "        #normalize,\n", "    ])\n", "    val_test_tsfm = transforms.Compose([\n", "        transforms.ToPILImage(),\n", "        transforms.Resize(image_size, interpolation=PIL.Image.BICUBIC),\n", "        transforms.CenterCrop(image_size),\n", "        transforms.ToTensor(),\n", "        #normalize,\n", "    ])\n\n", "    # Load training images and corresponding labels\n", "    train_images, train_labels = parseData(basePath=args.data,filter_name=args.filter, label_paths=train_label_paths, class_names=class_names,set_name=\"Training set\")\n\n", "    # Load testing images and corresponding labels\n", "    test_images, test_labels = parseData(basePath=args.data, filter_name=args.filter, label_paths=test_label_paths, class_names=class_names,set_name=\"Testing set\")\n\n", "    # Upsamples the training data if args.upsample = True\n", "    # adds all images in class 0, 8 times in total it appears in the dataset 9 times\n", "    # adds all images in class 1, 4 times in total it appears in the dataset 5 times\n", "    # adds all images in class 2, 1 time in total it appears in the dataset 2 times\n", "    # adds all images in class 3, 1 time, but only the 2000 first images\n", "    if args.upsample:\n", "        c0_ind = [i for i, x in enumerate(train_labels) if x == 0]\n", "        c1_ind = [i for i, x in enumerate(train_labels) if x == 1]\n", "        c2_ind = [i for i, x in enumerate(train_labels) if x == 2]\n", "        c3_ind = [i for i, x in enumerate(train_labels) if x == 3]\n", "        for i in range(8):\n", "            for idx, val in enumerate(c0_ind):\n", "                train_labels.append(train_labels[val])\n", "                train_images.append(train_images[val])\n", "        for i in range(4):\n", "            for idx, val in enumerate(c1_ind):\n", "                train_labels.append(train_labels[val])\n", "                train_images.append(train_images[val])\n", "        for i in range(1):\n", "            for idx, val in enumerate(c2_ind):\n", "                train_labels.append(train_labels[val])\n", "                train_images.append(train_images[val])\n", "        for idx, val in enumerate(c3_ind):\n", "            if idx < 2000:\n", "                train_labels.append(train_labels[val])\n", "                train_images.append(train_images[val])\n", "        print(class_names[0], \"appears\", len(c0_ind), \"times in the non augmented training and validation set\")\n", "        print(class_names[0], \"appears\", len([i for i, x in enumerate(train_labels) if x == 0]), \"times in the augmented training and validation set\")\n", "        print(class_names[1], \"appears\", len(c1_ind), \"times in the non augmented training and validation set\")\n", "        print(class_names[1], \"appears\", len([i for i, x in enumerate(train_labels) if x == 1]), \"times in the augmented training and validation set\")\n", "        print(class_names[2], \"appears\", len(c2_ind), \"times in the non augmented training and validation set\")\n", "        print(class_names[2], \"appears\", len([i for i, x in enumerate(train_labels) if x == 2]), \"times in the augmented training and validation set\")\n", "        print(class_names[3], \"appears\", len(c3_ind), \"times in the non augmented training and validation set\")\n", "        print(class_names[3], \"appears\", len([i for i, x in enumerate(train_labels) if x == 3]), \"times in the augmented training and validation set\")\n\n", "    # Shuffles the training set\n", "    temp = list(zip(train_labels, train_images))\n", "    random.shuffle(temp)\n", "    train_labels, train_images = zip(*temp)\n\n", "    # Creates a StratifiedKfold Object with the number of splits, shuffle option and seed\n", "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=args.seed)\n\n", "    # Define device for the tensors\n", "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n", "    mp.set_start_method('spawn')\n\n", "    # Transform the test dataset to torch tensor, x is images and y is labels\n", "    tensor_test_images = torch.tensor(test_images, dtype=torch.float32, device=device)\n", "    tensor_test_labels = torch.tensor(test_labels, dtype=torch.long, device=device)\n", "    tensor_test_images = tensor_test_images.permute(0, 3, 1, 2)\n", "    split_counter = 0\n", "    # Generates indices and data split into training and test set\n", "    for train, val in skf.split(train_images, train_labels):\n", "        print(\"split:\",split_counter)\n", "        # Creates weights for run_model\n", "        num_item_per_class = [len([i for i, x in enumerate([train_labels[j] for j in train]) if x == n]) for n in range(num_classes)]\n", "        print(num_item_per_class)\n\n", "        # Transform the training and validation dataset to torch tensors, according to current split\n", "        # x is images and y is labels\n", "        tensor_train_images = torch.tensor([train_images[i] for i in train], dtype=torch.float32, device=device)\n", "        tensor_val_images = torch.tensor([train_images[i] for i in val], dtype=torch.float32, device=device)\n", "        tensor_train_labels = torch.tensor([train_labels[i] for i in train], dtype=torch.long, device=device)\n", "        tensor_val_labels = torch.tensor([train_labels[i] for i in val], dtype=torch.long, device=device)\n\n", "        # Order array dimensions to pytorch standard\n", "        # Changing format from <batch size, image height, image width, image channel>\n", "        # to <batch size, image channel, image height, image width>.\n", "        tensor_train_images = tensor_train_images.permute(0, 3, 1, 2)\n", "        tensor_val_images = tensor_val_images.permute(0, 3, 1, 2)\n\n", "        # Creates 3 CustomDataset Objects with the corresponding transform and image- and label tensors, to be able to use DataLoader\n", "        train_dataset = CustomDataset(tensors=(tensor_train_images, tensor_train_labels),\n", "                                    transform=train_tsfm)\n", "        val_dataset = CustomDataset(tensors=(tensor_val_images, tensor_val_labels),\n", "                                  transform=val_test_tsfm)\n", "        test_dataset = CustomDataset(tensors=(tensor_test_images, tensor_test_labels),\n", "                                   transform=val_test_tsfm)\n\n", "        # Prints the sizes of the three datasets\n", "        train_dataset_size = len(train_dataset)\n", "        val_dataset_size = len(val_dataset)\n", "        test_dataset_size = len(test_dataset)\n", "        print(\"train size: {}\".format(train_dataset_size))\n", "        print(\"val size: {}\".format(val_dataset_size))\n", "        print(\"test size: {}\".format(test_dataset_size))\n\n", "        # Creates DataLoaders for each dataset to use for training\n", "        train_loader = torch.utils.data.DataLoader(\n", "            train_dataset, batch_size=args.batch_size, shuffle=shuffle,\n", "            num_workers=args.workers, pin_memory=False)\n", "        val_loader = torch.utils.data.DataLoader(\n", "            val_dataset,\n", "            batch_size=args.batch_size, shuffle=False,\n", "            num_workers=args.workers, pin_memory=False)\n", "        test_loader = torch.utils.data.DataLoader(\n", "            test_dataset,\n", "            batch_size=args.batch_size, shuffle=False,\n", "            num_workers=args.workers, pin_memory=False)\n", "        #Creates a dictionary with the three dataloaders\n", "        loaders = {\n", "            \"train\": train_loader,\n", "            \"val\": val_loader,\n", "            \"test\": test_loader\n", "        }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #Sarts training for each k-fold and saves it in model\n", "        model = run_model(loaders, split_counter, args, class_names,num_item_per_class)\n", "        split_counter += 1\n\n", "    # View results of model\n", "    # visualize_model(model, my_dataloader)\n", "    # plt.show()\n\n", "    # View single image\n", "    # crop = Image.fromarray(images[5814])\n", "    # crop.show()\n", "    # print(labels[5814])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}