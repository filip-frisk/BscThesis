{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipfusk/BscThesis/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU1osYvTXH8E"
      },
      "source": [
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "import argparse\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQh4FPPfXJob"
      },
      "source": [
        "djahlksdjhslk bd qwkjn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbAgsdlpXH8H"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.multiprocessing as mp\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import time\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7adg_zAXH8I"
      },
      "source": [
        "from parseData import parseData\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GteWd549XH8J"
      },
      "source": [
        "from visualize_model import visualize_model\n",
        "from train_valid_split import train_valid_split\n",
        "from run_model import run_model\n",
        "from CellDataset import CellDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJs7JCmWXH8J"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2zXlMHuXH8J"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='PyTorch EfficientNet Training')\n",
        "parser.add_argument('--data', metavar='DIR', default=\"KI-dataset-4-types/All_Slices/\",\n",
        "                    help='path to KI-Dataset folder')\n",
        "parser.add_argument('-a', '--arch', metavar='ARCH', default='efficientnet-b0',\n",
        "                    help='model architecture (default: efficientnet-b0)')\n",
        "parser.add_argument('-j', '--workers', default=1, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 1)')\n",
        "parser.add_argument('--epochs', default=15, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('-b', '--batch-size', default=8, type=int,\n",
        "                    metavar='N',\n",
        "                    help='mini-batch size (default:8), this is the total '\n",
        "                         'batch size of all GPUs on the current node when '\n",
        "                         'using Data Parallel or Distributed Data Parallel')\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
        "                    metavar='LR', help='initial learning rate', dest='lr')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum')\n",
        "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)',\n",
        "                    dest='weight_decay')\n",
        "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
        "                    metavar='N', help='print frequency (default: 10)')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
        "                    help='evaluate model on test set')\n",
        "parser.add_argument('-val', '--validate', dest='validate', action='store_true',\n",
        "                    help='evaluate model on validation set')\n",
        "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
        "                    help='use pre-trained model')\n",
        "parser.add_argument('--feature_extract', dest='feature_extract',\n",
        "                    action='store_true',\n",
        "                    help=\"Train only last layer (otherwise full model)\")\n",
        "parser.add_argument('--seed', default=None, type=int,\n",
        "                    help='seed for initializing training. ')\n",
        "parser.add_argument('--gpu', default=None, type=int,\n",
        "                    help='GPU id to use.')\n",
        "parser.add_argument('--image_size', default=32, type=int,\n",
        "                    help='image size')\n",
        "parser.add_argument('--advprop', default=False, action='store_true',\n",
        "                    help='use advprop or not')\n",
        "parser.add_argument('--upsample', default=True, action='store_true',\n",
        "                    help='upsample, else use class weights')\n",
        "parser.add_argument('--filter', default=\"\",\n",
        "                    help='filter we want to use for training the model')\n",
        "parser.add_argument('--outdest', default=\"\",\n",
        "                    help='where we want to save our output data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7NybMSMXH8K"
      },
      "source": [
        "Static config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ago6cGhkXH8L"
      },
      "source": [
        "num_classes = 4\n",
        "class_names = ['inflammatory', 'lymphocyte', 'fibroblast and endothelial',\n",
        "               'epithelial', 'apoptosis / civiatte body']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Wa-TdYXH8N"
      },
      "source": [
        "train_label_paths = [\n",
        "    \"P19_1_1\",\n",
        "    \"P19_1_2\",\n",
        "    \"P19_2_1\",\n",
        "    \"P19_2_2\",\n",
        "    \"P19_3_1\",\n",
        "    \"P19_3_2\",\n",
        "    \"P20_1_3\",\n",
        "    \"P20_1_4\",\n",
        "    \"P20_2_2\",\n",
        "    \"P20_2_3\",\n",
        "    \"P20_2_4\",\n",
        "    \"P20_3_1\",\n",
        "    \"P20_3_2\",\n",
        "    \"P20_3_3\",\n",
        "    \"P20_4_1\",\n",
        "    \"P20_4_2\",\n",
        "    \"P20_4_3\",\n",
        "    \"P20_5_1\",\n",
        "    \"P20_5_2\",\n",
        "    \"P20_6_1\",\n",
        "    \"P20_6_2\",\n",
        "    \"P20_7_1\",\n",
        "    \"P20_7_2\",\n",
        "    \"P20_8_1\",\n",
        "    \"P20_8_2\",\n",
        "    \"P20_9_1\",\n",
        "    \"P20_9_2\",\n",
        "    \"P9_1_1\",\n",
        "    \"P9_2_1\",\n",
        "    \"P9_2_2\",\n",
        "    \"P9_3_1\",\n",
        "    \"P9_3_2\",\n",
        "    \"P9_4_1\",\n",
        "    \"P9_4_2\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-stzD4NsXH8N"
      },
      "source": [
        "test_label_paths = [\n",
        "    \"N10_1_1\",\n",
        "    \"N10_1_2\",\n",
        "    \"N10_1_3\",\n",
        "    \"N10_2_1\",\n",
        "    \"N10_2_2\",\n",
        "    \"P13_1_1\",\n",
        "    \"P13_1_2\",\n",
        "    \"P13_2_1\",\n",
        "    \"P13_2_2\",\n",
        "    \"P28_7_5\",\n",
        "    \"P28_8_5\",\n",
        "    \"P28_10_4\",\n",
        "    \"P28_10_5\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWO9vSvLXH8O"
      },
      "source": [
        "shuffle = True\n",
        "k = 5 # Cross-validation splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Z3mp-FXH8O"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gHNyYtyXH8O"
      },
      "source": [
        "def lambdaTransform(image):\n",
        "    return image * 2.0 - 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW3Gc39QXH8P"
      },
      "source": [
        "def main():\n",
        "    args = parser.parse_args()\n",
        "    print(torch.version.cuda)\n",
        "    a = torch.cuda.FloatTensor([1.])\n",
        "    print(a)\n",
        "    image_size = args.image_size\n",
        "    print('Using image size: ', image_size)\n",
        "    filter = args.filter\n",
        "    print('Using filter ', filter)\n",
        "    train_tsfm = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(image_size+math.floor(0.1*image_size), interpolation=PIL.Image.BICUBIC),\n",
        "        transforms.RandomResizedCrop(image_size),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        AddGaussianNoise(0., 0.1)\n",
        "        #normalize,\n",
        "    ])\n",
        "    val_tsfm = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize(image_size, interpolation=PIL.Image.BICUBIC),\n",
        "        transforms.CenterCrop(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        #normalize,\n",
        "    ])\n",
        "\n",
        "    # Load and split datasets and convert to tensor\n",
        "    # Test images from different slices than train\n",
        "    train_images, train_labels = parseData(basePath=args.data,filter_name=filter, label_paths=train_label_paths, class_names=class_names)\n",
        "\n",
        "    # remove all images in training set with labels 4\n",
        "    for i in range(len(train_labels)-1, -1, -1):\n",
        "        if(train_labels[i] == 4):\n",
        "            train_labels.pop(i)\n",
        "            train_images.pop(i)\n",
        "    test_images, test_labels = parseData(basePath=args.data, filter_name=filter, label_paths=test_label_paths, class_names=class_names)\n",
        "    for i in range(len(test_labels)-1, -1, -1):\n",
        "        if(test_labels[i] == 4):\n",
        "            test_labels.pop(i)\n",
        "            test_images.pop(i)\n",
        "\n",
        "    # Upsamples the training data if args.upsample = True\n",
        "    if args.upsample:\n",
        "        c0_ind = [i for i, x in enumerate(train_labels) if x == 0]\n",
        "        c1_ind = [i for i, x in enumerate(train_labels) if x == 1]\n",
        "        c2_ind = [i for i, x in enumerate(train_labels) if x == 2]\n",
        "        c3_ind = [i for i, x in enumerate(train_labels) if x == 3]\n",
        "        for i in range(8):\n",
        "            for idx, val in enumerate(c0_ind):\n",
        "                train_labels.append(train_labels[val])\n",
        "                train_images.append(train_images[val])\n",
        "        for i in range(4):\n",
        "            for idx, val in enumerate(c1_ind):\n",
        "                train_labels.append(train_labels[val])\n",
        "                train_images.append(train_images[val])\n",
        "        for i in range(1):\n",
        "            for idx, val in enumerate(c2_ind):\n",
        "                train_labels.append(train_labels[val])\n",
        "                train_images.append(train_images[val])\n",
        "        for idx, val in enumerate(c3_ind):\n",
        "            if idx < 2000:\n",
        "                train_labels.append(train_labels[val])\n",
        "                train_images.append(train_images[val])\n",
        "    temp = list(zip(train_labels, train_images))\n",
        "    random.shuffle(temp)\n",
        "    train_labels, train_images = zip(*temp)\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=args.seed)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    mp.set_start_method('spawn')\n",
        "\n",
        "    # Transform to torch tensor\n",
        "    tensor_test_x = torch.tensor(test_images, dtype=torch.float32, device=device)\n",
        "    tensor_test_y = torch.tensor(test_labels, dtype=torch.long, device=device)\n",
        "    tensor_test_x = tensor_test_x.permute(0, 3, 1, 2)\n",
        "    split = 0\n",
        "    for train, val in skf.split(train_images, train_labels):\n",
        "        tensor_train_x = torch.tensor([train_images[i] for i in train], dtype=torch.float32, device=device)\n",
        "        tensor_val_x = torch.tensor([train_images[i] for i in val], dtype=torch.float32, device=device)\n",
        "        tensor_train_y = torch.tensor([train_labels[i] for i in train], dtype=torch.long, device=device)\n",
        "        tensor_val_y = torch.tensor([train_labels[i] for i in val], dtype=torch.long, device=device)\n",
        "\n",
        "        # Order array dimensions to pytorch standard\n",
        "        tensor_train_x = tensor_train_x.permute(0, 3, 1, 2)\n",
        "        tensor_val_x = tensor_val_x.permute(0, 3, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxlUmdtbXH8P"
      },
      "source": [
        "        train_dataset = CellDataset(tensors=(tensor_train_x, tensor_train_y),\n",
        "                                    transform=train_tsfm)\n",
        "        val_dataset = CellDataset(tensors=(tensor_val_x, tensor_val_y),\n",
        "                                  transform=val_tsfm)\n",
        "        test_dataset = CellDataset(tensors=(tensor_test_x, tensor_test_y),\n",
        "                                   transform=val_tsfm)\n",
        "\n",
        "        # Sizes of datasets\n",
        "        train_dataset_size = len(train_dataset)\n",
        "        val_dataset_size = len(val_dataset)\n",
        "        test_dataset_size = len(test_dataset)\n",
        "        print(\"train size: {}\".format(train_dataset_size))\n",
        "        print(\"val size: {}\".format(val_dataset_size))\n",
        "        print(\"test size: {}\".format(test_dataset_size))\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=args.batch_size, shuffle=shuffle,\n",
        "            num_workers=args.workers, pin_memory=False)\n",
        "        val_loader = torch.utils.data.DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=args.batch_size, shuffle=False,\n",
        "            num_workers=args.workers, pin_memory=False)\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=args.batch_size, shuffle=False,\n",
        "            num_workers=args.workers, pin_memory=False)\n",
        "        loaders = {\n",
        "            \"train\": train_loader,\n",
        "            \"val\": val_loader,\n",
        "            \"test\": test_loader\n",
        "        }\n",
        "        model = run_model(loaders, split, args, class_names)\n",
        "        split += 1\n",
        "\n",
        "    # View results of model\n",
        "    # visualize_model(model, my_dataloader)\n",
        "    # plt.show()\n",
        "\n",
        "    # View single image\n",
        "    # crop = Image.fromarray(images[5814])\n",
        "    # crop.show()\n",
        "    # print(labels[5814])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OswS1A0MXH8Q"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}