{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking in TIF, normalize the Image without taking white parts into account<br>\n",
    "Cropping 32x32 images around the center of the cells<br>\n",
    "All images are stored in the array \"images \"and the labels are stored in array labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: parseData<br>\n",
    "Function: Parse data from .xml and .tif file to arrays<br>\n",
    "Input: File paths and names, filter name, class names and type of dataset<br>\n",
    "Output: Cropped images of each cell and associated label (Cell type) found from input<br>\n",
    "All images are represented with a .tif-file and an associated .xml-file<br>\n",
    "Structure in .xml file from labelIMG python library used by KI:<br>\n",
    "Each object has: Name (cell type) and bounding box<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(basePath=\"KI-dataset-4-types/All_Slices/\", filter_name= \"\", label_paths=\"\", class_names=[],set_name=\"No input name\"):\n",
    "\n",
    "    # Creates empty lists for output, calculates number of files to be loaded and prints type of dataset\n",
    "    fileCount = len(label_paths)\n",
    "    labels = []\n",
    "    images = []\n",
    "    print(set_name,\": \")\n",
    "\n",
    "    # Iterates over every file\n",
    "    for path in range(fileCount):\n",
    "        # Using PIL library to import files\n",
    "        image = basePath+label_paths[path]+filter_name+'.tif'\n",
    "        im = Image.open(image)\n",
    "\n",
    "        # Parse full image to nparray and normalizes the image without taking into account the white background\n",
    "        # Pixels with mean values over 0.95 are considered white and are ignored\n",
    "        imarray = np.array(im, dtype=np.double)/255 #255 is max pixel value)\n",
    "        B = imarray.copy()\n",
    "        means = B.mean(axis=2)\n",
    "        B[means > 0.95,:] = np.nan #Nan = ignore\n",
    "        mean = np.nanmean(B, axis=(0,1))\n",
    "        std = np.nanstd(B, axis=(0,1))\n",
    "        imarray = (imarray - mean) / std # Normalization\n",
    "\n",
    "        # Creates a xml tree from current file\n",
    "        tree = ET.parse(basePath + label_paths[path] + '.xml')\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Loop through xml label tree\n",
    "        for child in root.iter('object'):\n",
    "            # Parse label\n",
    "            for name in child.iter('name'):\n",
    "                label = name.text\n",
    "\n",
    "                # One .xml file had <name> w </name> which is handled here, which we decided to delete (N10_1_1)\n",
    "                if label == 'w':\n",
    "                    print(label_paths[path])\n",
    "                    print(len(labels))\n",
    "\n",
    "                # Appends corresponding label index from class_names to labels (numpy array)\n",
    "                # class_names = ['inflammatory', 'lymphocyte', 'fibroblast and endothelial', 'epithelial', 'apoptosis / civiatte body']\n",
    "                # corresponding indices = [0,1,2,3,4]\n",
    "                labels.append(class_names.index(label))\n",
    "\n",
    "            # Parse matching image data\n",
    "            for box in child.iter('bndbox'):\n",
    "                #Crates boundry array\n",
    "                boundaries = []\n",
    "                for coordinate in box.iter():\n",
    "                    boundaries.append(coordinate.text)\n",
    "\n",
    "                # Get center of crop and make sure the box fits inside of image\n",
    "                center_X = int((int(boundaries[1]) + int(boundaries[3])) / 2)\n",
    "                center_X = max(center_X, 16)\n",
    "                center_X = min(center_X, imarray.shape[1]-16)\n",
    "                center_Y = int((int(boundaries[2]) + int(boundaries[4])) / 2)\n",
    "                center_Y = max(center_Y, 16)\n",
    "                center_Y = min(center_Y, imarray.shape[0]-16)\n",
    "\n",
    "                # Appends corresponding cropped to images\n",
    "                # Cropping 32x32 images around the center of the cells\n",
    "                cropArray = imarray[center_Y-16:center_Y+16, center_X-16:center_X+16, :]\n",
    "                images.append(cropArray)\n",
    "\n",
    "        # Print the current file name to terminal after successful parsing\n",
    "        print(\"Successfully loaded:\", label_paths[path])\n",
    "\n",
    "    # Remove all images in training set with labels 4 ('apoptosis / civiatte body'), not used in study\n",
    "    for i in range(len(labels) - 1, -1, -1):\n",
    "        if (labels[i] == 4):\n",
    "            labels.pop(i)\n",
    "            images.pop(i)\n",
    "\n",
    "    return images, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
