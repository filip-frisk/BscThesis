{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import os\n", "import random\n", "import shutil\n", "import time\n", "import warnings\n", "import PIL\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.parallel\n", "import torch.backends.cudnn as cudnn\n", "import torch.distributed as dist\n", "import torch.optim\n", "import torch.multiprocessing as mp\n", "import torch.utils.data\n", "import torch.utils.data.distributed\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as datasets\n", "import torchvision.models as models\n", "from sklearn.metrics import classification_report\n", "from efficientnet_pytorch import EfficientNet\n", "from CellDataset import CellDataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_acc1 = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LOL config<br>\n", " HIHI config<br>\n", "# Static config<br>\n", "## Statiscalksdjalskdhakljsha"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_classes = 4"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Train/validate an EfficentNet model<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_model(loaders, split, args, class_names):\n", "    if args.seed is not None:\n", "        random.seed(args.seed)\n", "        torch.manual_seed(args.seed)\n", "        cudnn.deterministic = True\n", "        warnings.warn('You have chosen to seed training. '\n", "                      'This will turn on the CUDNN deterministic setting, '\n", "                      'which can slow down your training considerably! '\n", "                      'You may see unexpected behavior when restarting '\n", "                      'from checkpoints.')\n", "    if args.gpu is not None:\n", "        warnings.warn('You have chosen a specific GPU. This will completely '\n", "                      'disable data parallelism.')\n", "    ngpus = torch.cuda.device_count()\n", "    print(\"Available GPUs: {}\".format(ngpus))\n", "    return main_worker(loaders, split, args.gpu, ngpus, args)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main_worker(loaders, split, gpu, ngpus, args):\n", "    global best_acc1\n", "    args.gpu = gpu\n", "    output_destination = args.outdest\n", "    if args.gpu is not None:\n", "        print(\"Use GPU: {} for training\".format(args.gpu))\n\n", "    # create model\n", "    if 'efficientnet-b' in args.arch:  # NEW\n", "        if args.pretrained:\n", "            model = EfficientNet.from_pretrained(args.arch, advprop=args.advprop, num_classes=num_classes)\n", "            print(\"=> using pre-trained model '{}'\".format(args.arch))\n", "        else:\n", "            print(\"=> creating model '{}'\".format(args.arch))\n", "            model = EfficientNet.from_name(args.arch, override_params={'num_classes': num_classes})\n", "    else:\n", "        print(\"Only EfficientNet models are supported.\")\n", "        quit()\n\n", "    # If specific GPU\n", "    if args.gpu is not None:\n", "        torch.cuda.set_device(args.gpu)\n", "        model = model.cuda(args.gpu)\n", "    else:\n", "        # Check if CUDA is available\n", "        if torch.cuda.is_available():\n", "            model = torch.nn.DataParallel(model).cuda()\n", "        else:\n", "            model.to(\"cpu\")\n\n", "    # Class weights = (total_count - class_count) / total_count\n", "    weights = [25137/2017, 25137/3211, 25137/7296, 25137/12519]\n", "    weights = [(25137-2017)/25137, (25137-3211)/25137, (25137-7296)/25137, (25137-12519)/25137]\n", "    class_weights = torch.FloatTensor(weights)\n", "    if torch.cuda.is_available():\n", "        class_weights = class_weights.cuda()\n\n", "    # Define loss function (criterion) and optimizer\n", "    if torch.cuda.is_available():\n", "        criterion = nn.CrossEntropyLoss(weight=class_weights).cuda(args.gpu)\n", "        if args.upsample:\n", "            criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n", "    else:\n", "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n", "        if args.upsample:\n", "            criterion = nn.CrossEntropyLoss()\n", "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n", "                                nesterov=True,\n", "                                momentum=args.momentum,\n", "                                weight_decay=args.weight_decay)\n", "    #optimizer = torch.optim.AdamW(model.parameters(), args.lr,weight_decay=args.weight_decay, amsgrad=True)\n", "    # optionally resume from a checkpoint\n", "    if args.resume:\n", "        if os.path.isfile(args.resume):\n", "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n", "            checkpoint = torch.load(args.resume)\n", "            args.start_epoch = checkpoint['epoch']\n", "            best_acc1 = checkpoint['best_acc1']\n", "            if args.gpu is not None:\n", "                # best_acc1 may be from a checkpoint from a different GPU\n", "                best_acc1 = best_acc1.to(args.gpu)\n", "            model.load_state_dict(checkpoint['state_dict'])\n", "            optimizer.load_state_dict(checkpoint['optimizer'])\n", "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n", "                  .format(args.resume, checkpoint['epoch']))\n", "        else:\n", "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n", "    cudnn.benchmark = True\n\n", "    # Only unfreeze classification layer\n", "    if args.feature_extract:\n", "        c = 0\n", "        for param in model.parameters():\n", "            c+= 1\n", "            if c < 213:\n", "                param.requires_grad = False\n", "    for epoch in range(args.start_epoch, args.epochs):\n", "        adjust_learning_rate(optimizer, epoch, args)\n\n", "        # train for one epoch\n", "        train(loaders['train'], model, criterion, optimizer, epoch, args)\n\n", "        # evaluate on validation set\n", "        acc1, _ = validate(loaders['val'], model, criterion, args)\n\n", "        # remember best acc@1 and save checkpoint\n", "        is_best = acc1 > best_acc1\n", "        best_acc1 = max(acc1, best_acc1)\n", "        save_checkpoint({\n", "            'epoch': epoch + 1,\n", "            'arch': args.arch,\n", "            'state_dict': model.state_dict(),\n", "            'best_acc1': best_acc1,\n", "            'optimizer': optimizer.state_dict(),\n", "        }, is_best, split,output_destination)\n", "    if args.validate:\n", "        res, classification = validate(loaders['val'], model, criterion, args)\n", "        with open(output_destination + '/res_val_{}.txt'.format(split), 'w') as f:\n", "            print(res, file=f)\n", "            print(classification, file=f)\n", "    if args.evaluate:\n", "        res, classification = validate(loaders['test'], model, criterion, args)\n", "        with open(output_destination + '/res_test_{}.txt'.format(split), 'w') as f:\n", "            print(res, file=f)\n", "            print(classification, file=f)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(train_loader, model, criterion, optimizer, epoch, args):\n", "    batch_time = AverageMeter('Time', ':6.3f')\n", "    data_time = AverageMeter('Data', ':6.3f')\n", "    losses = AverageMeter('Loss', ':.4e')\n", "    top1 = AverageMeter('Acc@1', ':6.2f')\n", "    progress = ProgressMeter(len(train_loader), batch_time, data_time, losses, top1,\n", "                              prefix=\"Epoch: [{}]\".format(epoch))\n\n", "    # switch to train mode\n", "    model.train()\n", "    end = time.time()\n", "    for i, (images, target) in enumerate(train_loader):\n", "        # measure data loading time\n", "        data_time.update(time.time() - end)\n", "        if args.gpu is not None:\n", "            images = images.cuda(args.gpu, non_blocking=True)\n", "        if torch.cuda.is_available():\n", "            target = target.cuda(args.gpu, non_blocking=True)\n\n", "        # compute output\n", "        output = model(images)\n", "        loss = criterion(output, target)\n\n", "        # measure accuracy and record loss\n", "        acc1 = accuracy(output, target, topk=(1,))\n", "        losses.update(loss.item(), images.size(0))\n", "        top1.update(acc1[0].item(), images.size(0))\n\n", "        # compute gradient and do SGD step\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n\n", "        # measure elapsed time\n", "        batch_time.update(time.time() - end)\n", "        end = time.time()\n", "        if i % args.print_freq == 0:\n", "            progress.print(i)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def validate(val_loader, model, criterion, args):\n", "    batch_time = AverageMeter('Time', ':6.3f')\n", "    losses = AverageMeter('Loss', ':.4e')\n", "    top1 = AverageMeter('Acc@1', ':6.2f')\n", "    topC1 = AverageMeter('Acc C1', ':6.2f')\n", "    topC2 = AverageMeter('Acc C2', ':6.2f')\n", "    topC3 = AverageMeter('Acc C3', ':6.2f')\n", "    topC4 = AverageMeter('Acc C4', ':6.2f')\n", "    progress = ProgressMeter(len(val_loader), batch_time, losses, top1, topC1, topC2, topC3, topC4,\n", "                             prefix='Test: ')\n\n", "    # switch to evaluate mode\n", "    model.eval()\n", "    y_true, y_pred = [], []\n", "    with torch.no_grad():\n", "        end = time.time()\n", "        for i, (images, target) in enumerate(val_loader):\n", "            if args.gpu is not None:\n", "                images = images.cuda(args.gpu, non_blocking=True)\n", "            if torch.cuda.is_available():\n", "                target = target.cuda(args.gpu, non_blocking=True)\n\n", "            # compute output\n", "            output = model(images)\n", "            loss = criterion(output, target)\n\n", "            # measure accuracy and record loss\n", "            acc1 = accuracy(output, target, topk=(1,))\n", "            losses.update(loss.item(), images.size(0))\n", "            top1.update(acc1[0].item(), images.size(0))\n", "            _, pred = output.topk(1, 1, True, True)\n", "            pred = pred.t()\n", "            y_true.extend(target.detach().cpu().numpy())\n", "            y_pred.extend(pred.detach().cpu().numpy()[0])\n", "            C1indices = [index for index, element in enumerate(target) if element == 0]\n", "            if len(C1indices) > 0:\n", "                accC1 = accuracy(output[C1indices], target[C1indices], topk=(1,))\n", "                topC1.update(accC1[0].item(), len(C1indices))\n", "            C2indices = [index for index, element in enumerate(target) if element == 1]\n", "            if len(C2indices) > 0:\n", "                accC2 = accuracy(output[C2indices], target[C2indices], topk=(1,))\n", "                topC2.update(accC2[0].item(), len(C2indices))\n", "            C3indices = [index for index, element in enumerate(target) if element == 2]\n", "            if len(C3indices) > 0:\n", "                accC3 = accuracy(output[C3indices], target[C3indices], topk=(1,))\n", "                topC3.update(accC3[0].item(), len(C3indices))\n", "            C4indices = [index for index, element in enumerate(target) if element == 3]\n", "            if len(C4indices) > 0:\n", "                accC4 = accuracy(output[C4indices], target[C4indices], topk=(1,))\n", "                topC4.update(accC4[0].item(), len(C4indices))\n\n", "            # measure elapsed time\n", "            batch_time.update(time.time() - end)\n", "            end = time.time()\n", "            if i % args.print_freq == 0:\n", "                progress.print(i)\n\n", "        # TODO: this should also be done with the ProgressMeter\n", "        print(' * Acc {top1.avg:.3f}'\n", "              .format(top1=top1))\n", "    report = classification_report(y_true, y_pred)\n", "    print(report)\n", "    return top1.avg, report"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TODO Albert Filip have main checkpoint in folder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_checkpoint(state, is_best, split, destination ,filename='checkpoint.pth.tar'):\n", "    torch.save(state, filename)\n", "    if is_best:\n", "        shutil.copyfile(filename, destination + '/model_best_{}.pth.tar'.format(split))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AverageMeter(object):\n", "    \"\"\"Computes and stores the average and current value\"\"\"\n", "    def __init__(self, name, fmt=':f'):\n", "        self.name = name\n", "        self.fmt = fmt\n", "        self.reset()\n", "    def reset(self):\n", "        self.val = 0\n", "        self.avg = 0\n", "        self.sum = 0\n", "        self.count = 0\n", "    def update(self, val, n=1):\n", "        self.val = val\n", "        self.sum += val * n\n", "        self.count += n\n", "        self.avg = self.sum / self.count\n", "    def __str__(self):\n", "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n", "        return fmtstr.format(**self.__dict__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ProgressMeter(object):\n", "    def __init__(self, num_batches, *meters, prefix=\"\"):\n", "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n", "        self.meters = meters\n", "        self.prefix = prefix\n", "    def print(self, batch):\n", "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n", "        entries += [str(meter) for meter in self.meters]\n", "        print('\\t'.join(entries))\n", "    def _get_batch_fmtstr(self, num_batches):\n", "        num_digits = len(str(num_batches // 1))\n", "        fmt = '{:' + str(num_digits) + 'd}'\n", "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def adjust_learning_rate(optimizer, epoch, args):\n", "    \"\"\"Sets the learning rate to the initial LR decayed by 3% every 2.4 epochs\"\"\"\n", "    lr = args.lr * (0.97 ** (epoch // 2.4))\n", "    for param_group in optimizer.param_groups:\n", "        param_group['lr'] = lr"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def accuracy(output, target, topk=(1,)):\n", "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n", "    with torch.no_grad():\n", "        maxk = max(topk)\n", "        batch_size = target.size(0)\n", "        _, pred = output.topk(maxk, 1, True, True)\n", "        pred = pred.t()\n", "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n", "        res = []\n", "        for k in topk:\n", "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n", "            res.append(correct_k.mul_(100.0 / batch_size))\n", "        return res"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}