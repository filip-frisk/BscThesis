{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["A varitation of the emsemble.py file, used for esembling 4 models at a time<br>\n", "(this was the ensemble used in the final report)<br>\n", "Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from run_model import AverageMeter, ProgressMeter, confusion_matix_string,accuracy\n", "from sklearn.metrics import classification_report\n", "from CustomDataset import CustomDataset\n", "from parseData import parseData\n", "import argparse\n", "import torch\n", "from efficientnet_pytorch import EfficientNet\n", "from torchvision import datasets, models, transforms\n", "import torch.multiprocessing as mp\n", "import PIL\n", "import torch.nn as nn\n", "import torch.backends.cudnn as cudnn\n", "import time\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["arser arguments"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = argparse.ArgumentParser(description='PyTorch EfficientNet Training')\n", "parser.add_argument('--data', metavar='DIR', default=\"KI-dataset-4-types/All_Slices/\",\n", "                    help='path to KI-Dataset folder')\n", "parser.add_argument('-a', '--arch', metavar='ARCH', default='efficientnet-b0',\n", "                    help='model architecture (default: efficientnet-b0)')\n", "parser.add_argument('-j', '--workers', default=1, type=int, metavar='N',\n", "                    help='number of data loading workers (default: 1)')\n", "parser.add_argument('--epochs', default=15, type=int, metavar='N',\n", "                    help='number of total epochs to run')\n", "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n", "                    help='manual epoch number (useful on restarts)')\n", "parser.add_argument('-b', '--batch-size', default=8, type=int,\n", "                    metavar='N',\n", "                    help='mini-batch size (default:8), this is the total '\n", "                         'batch size of all GPUs on the current node when '\n", "                         'using Data Parallel or Distributed Data Parallel')\n", "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n", "                    metavar='LR', help='initial learning rate', dest='lr')\n", "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n", "                    help='momentum')\n", "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n", "                    metavar='W', help='weight decay (default: 1e-4)',\n", "                    dest='weight_decay')\n", "parser.add_argument('-p', '--print-freq', default=10, type=int,\n", "                    metavar='N', help='print frequency (default: 10)')\n", "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n", "                    help='path to latest checkpoint (default: none)')\n", "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n", "                    help='evaluate model on test set')\n", "parser.add_argument('-val', '--validate', dest='validate', action='store_true',\n", "                    help='evaluate model on validation set')\n", "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n", "                    help='use pre-trained model')\n", "parser.add_argument('--feature_extract', dest='feature_extract',\n", "                    action='store_true',\n", "                    help=\"Train only last layer (otherwise full model)\")\n", "parser.add_argument('--seed', default=None, type=int,\n", "                    help='seed for initializing training. ')\n", "parser.add_argument('--gpu', default=None, type=int,\n", "                    help='GPU id to use.')\n", "parser.add_argument('--image_size', default=32, type=int,\n", "                    help='image size')\n", "parser.add_argument('--advprop', default=False, action='store_true',\n", "                    help='use advprop or not')\n", "parser.add_argument('--upsample', default=True, action='store_true',\n", "                    help='upsample, else use class weights')\n", "parser.add_argument('--filter', default=\"\",\n", "                    help='filter we want to use for training the model')\n", "parser.add_argument('--outdest', default=\"\",\n", "                    help='where we want to save our output data')\n", "parser.add_argument('--model_paths', default=[],\n", "                    help='path to models to be used')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Variables for experiment"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_classes = 4\n", "class_names = ['inflammatory', 'lymphocyte', 'fibroblast and endothelial',\n", "               'epithelial', 'apoptosis / civiatte body']\n", "filters = [\"\",\"_Macenko\",\"_Reinhard\",\"_SCD\"]\n", "y_pred_per_filter = {\"True\" : []}\n", "p_pred_per_filter = {}\n", "test_label_paths = [\n", "    \"N10_1_1\",\n", "    \"N10_1_2\",\n", "    \"N10_1_3\",\n", "    \"N10_2_1\",\n", "    \"N10_2_2\",\n", "    \"P13_1_1\",\n", "    \"P13_1_2\",\n", "    \"P13_2_1\",\n", "    \"P13_2_2\",\n", "    \"P28_7_5\",\n", "    \"P28_8_5\",\n", "    \"P28_10_4\",\n", "    \"P28_10_5\",\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    k = 4 # picks the k-th best model from training\n", "    args = parser.parse_args()\n", "    model_paths = [item for item in args.model_paths.split(\",\")]\n", "    print(model_paths)\n\n", "    # Define device for the tensors and enables multiprocessing\n", "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n", "    mp.set_start_method('spawn')\n", "    for filter, path in zip(filters, model_paths):\n\n", "        # prints the current filter to the terminal\n", "        if filter: print(filter.strip('_'))\n", "        else: print(\"No_filter\")\n\n", "        #Hardcoded destination from this project repository\n", "        #filename = \"model_best_{}.pth.tar\".format(k)\n", "        filename = \"model_best.pth.tar\"\n", "        test_images, test_labels = parseData(basePath=args.data, filter_name=filter, label_paths=test_label_paths,\n", "                                             class_names=class_names, set_name=\"Testing set\")\n\n", "        # Transform the test dataset to torch tensor, x is images and y is labels\n", "        tensor_test_images = torch.tensor(test_images, dtype=torch.float32, device=device)\n", "        tensor_test_labels = torch.tensor(test_labels, dtype=torch.long, device=device)\n", "        tensor_test_images = tensor_test_images.permute(0, 3, 1, 2)\n\n", "        #Define transform\n", "        test_tsfm = transforms.Compose([\n", "            transforms.ToPILImage(),\n", "            transforms.Resize(args.image_size, interpolation=PIL.Image.BICUBIC),\n", "            transforms.CenterCrop(args.image_size),\n", "            transforms.ToTensor(),\n", "        ])\n", "        test_dataset = CustomDataset(tensors=(tensor_test_images, tensor_test_labels),\n", "                                     transform=test_tsfm)\n", "        test_loader = torch.utils.data.DataLoader(\n", "            test_dataset,\n", "            batch_size=args.batch_size, shuffle=False,\n", "            num_workers=args.workers, pin_memory=False)\n", "        checkpoint = torch.load(path + filename)\n", "        args.arch = checkpoint['arch']\n\n", "        # Creates model using EfficientNet library\n", "        if 'efficientnet-b' in args.arch:  # NEW\n", "            if args.pretrained:\n", "                model = EfficientNet.from_pretrained(args.arch, advprop=args.advprop, num_classes=num_classes)\n", "                print(\"=> using pre-trained model '{}'\".format(args.arch))\n", "            else:\n", "                print(\"=> creating model '{}'\".format(args.arch))\n", "                model = EfficientNet.from_name(args.arch, override_params={'num_classes': num_classes})\n\n", "        # Handles the case where the user has specified GPU, to set the device manually\n", "        if args.gpu is not None:\n", "            torch.cuda.set_device(args.gpu)\n", "            model = model.cuda(args.gpu)\n", "        else:\n", "            # If GPU not specifiec check if CUDA is available, else use CPU\n", "            if torch.cuda.is_available():\n", "                model = torch.nn.DataParallel(model).cuda()\n", "            else:\n", "                model.to(\"cpu\")\n\n", "        # args.start_epoch = checkpoint['epoch']\n", "        # best_acc1 = checkpoint['best_acc1']\n\n", "        # Loads model from loaded state dictionary in checkpoint\n", "        #print(checkpoint['state_dict'].keys())\n", "        model.load_state_dict(checkpoint['state_dict'])\n\n", "        # creates and loads optimizer\n", "        optimizer = torch.optim.SGD(model.parameters(), args.lr,\n", "                                    nesterov=True,\n", "                                    momentum=args.momentum,\n", "                                    weight_decay=args.weight_decay)\n", "        optimizer.load_state_dict(checkpoint['optimizer'])\n\n", "        # Defines criterion for model\n", "        if torch.cuda.is_available():\n", "            criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n", "        else:\n", "            criterion = nn.CrossEntropyLoss()\n\n", "        # Enables the inbuilt cudnn auto-tuner to find the best algorithm to use for the hardware\n", "        cudnn.benchmark = True\n", "        y_pred, y_true, p_pred = getpred(test_loader, model, criterion, args, 'Test: ')\n", "        get_reporting(y_pred, y_true)\n\n", "        # Checks if y_true is the same in for all filters\n", "        if y_pred_per_filter[\"True\"]:\n", "            assert y_pred_per_filter[\"True\"] == y_true\n", "        else:\n", "            y_pred_per_filter[\"True\"] = y_true\n\n", "        # Saves the prediction in the dictionary\n", "        if filter:\n", "            y_pred_per_filter[filter] = y_pred\n", "        else:\n", "            y_pred_per_filter[\"No_filter\"] = y_pred\n\n", "        # Saves the prediction probabilites in the dictionary\n", "        if filter:\n", "            p_pred_per_filter[filter] = p_pred\n", "        else:\n", "            p_pred_per_filter[\"No_filter\"] = p_pred\n", "    print(\"Ensemble Top 1 majority voting:\")\n", "    get_reporting(ensemble_majority_voting(y_pred_per_filter), y_true)\n", "    f = open( args.outdest + \"top1_majority_voting_predictions.txt\", \"w\")\n", "    f.write(str(y_pred_per_filter))\n", "    f.close()\n", "    print(\"Ensemble Pontalba majority voting:\")\n", "    get_reporting(ensemble_pontalba(p_pred_per_filter), y_true)\n", "    f = open(args.outdest + \"pontalba_majority_voting_predictions.txt\", \"w\")\n", "    f.write(str(p_pred_per_filter))\n", "    f.close()\n", "    save_reporting(y_pred, y_true, filter)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ensemble_majority_voting(y_pred_per_filter):\n", "    all = [y_pred_per_filter[\"No_filter\"], y_pred_per_filter[\"_Macenko\"], y_pred_per_filter[\"_Reinhard\"], y_pred_per_filter[\"_SCD\"]]\n", "    all = np.array(all).transpose()\n", "    return [np.random.choice(np.flatnonzero(np.bincount(v) == np.bincount(v).max())) for v in all]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ensemble_pontalba(p_pred_per_filter):\n", "    all = np.array([p_pred_per_filter[\"No_filter\"], p_pred_per_filter[\"_Macenko\"], p_pred_per_filter[\"_Reinhard\"], p_pred_per_filter[\"_SCD\"]])\n", "    all = np.sum(all, axis=0) / all.shape[0]\n", "    return [v.argmax() for v in all]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_reporting(y_pred,y_true):\n", "    print(\"classification report:\")\n", "    print(classification_report(y_true, y_pred))\n", "    print(confusion_matix_string(y_true, y_pred))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_reporting(y_pred,y_true,filter):\n", "    f = open(args.outdest + \"classification_report.txt\", \"w\")\n", "    f.write('-------',str(filter),'-------')\n", "    f.write(str(classification_report(y_true, y_pred, output_dict=True)))\n", "    f.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def getpred(val_loader, model, criterion, args, testing_type):\n", "    batch_time = AverageMeter('Time', ':6.3f')\n", "    losses = AverageMeter('Loss', ':.4e')\n", "    top1 = AverageMeter('Acc@1', ':6.2f')\n", "    topC1 = AverageMeter('Acc C1', ':6.2f')\n", "    topC2 = AverageMeter('Acc C2', ':6.2f')\n", "    topC3 = AverageMeter('Acc C3', ':6.2f')\n", "    topC4 = AverageMeter('Acc C4', ':6.2f')\n", "    progress = ProgressMeter(len(val_loader), batch_time, losses, top1, topC1, topC2, topC3, topC4,\n", "                             prefix=testing_type)\n\n", "    # switch to evaluate mode\n", "    model.eval()\n", "    y_true, y_pred = [], []\n", "    p_pred = []\n", "    # Source https://github.com/DingXiaoH/RepVGG/blob/main/train.py\n", "    with torch.no_grad(): #All new tensors do not require gradient (requires_grad=False)\n", "        end = time.time()\n", "        # iterates over all batches\n", "        for i, (images, target) in enumerate(val_loader):\n", "            if args.gpu is not None:\n", "                images = images.cuda(args.gpu, non_blocking=True)\n", "            if torch.cuda.is_available():\n", "                target = target.cuda(args.gpu, non_blocking=True)\n\n", "            # compute output\n", "            output = model(images)\n", "            loss = criterion(output, target)\n\n", "            # measure accuracy and record loss\n", "            acc1 = accuracy(output, target, topk=(1,))\n", "            losses.update(loss.item(), images.size(0))\n", "            top1.update(acc1[0].item(), images.size(0))\n", "            _, pred = output.topk(1, 1, True, True)\n", "            pred = pred.t()\n\n", "            # extend y_true and y_pred with the prediction and true class\n", "            y_true.extend(target.detach().cpu().numpy())\n", "            y_pred.extend(pred.detach().cpu().numpy()[0])\n\n", "            # extend p_pred with the softmaxed predictions accuracies\n", "            softmax = nn.Softmax(dim=1)\n", "            p_pred.extend(softmax(output).detach().cpu().numpy())\n", "            C1indices = [index for index, element in enumerate(target) if element == 0]\n", "            if len(C1indices) > 0:\n", "                accC1 = accuracy(output[C1indices], target[C1indices], topk=(1,))\n", "                topC1.update(accC1[0].item(), len(C1indices))\n", "            C2indices = [index for index, element in enumerate(target) if element == 1]\n", "            if len(C2indices) > 0:\n", "                accC2 = accuracy(output[C2indices], target[C2indices], topk=(1,))\n", "                topC2.update(accC2[0].item(), len(C2indices))\n", "            C3indices = [index for index, element in enumerate(target) if element == 2]\n", "            if len(C3indices) > 0:\n", "                accC3 = accuracy(output[C3indices], target[C3indices], topk=(1,))\n", "                topC3.update(accC3[0].item(), len(C3indices))\n", "            C4indices = [index for index, element in enumerate(target) if element == 3]\n", "            if len(C4indices) > 0:\n", "                accC4 = accuracy(output[C4indices], target[C4indices], topk=(1,))\n", "                topC4.update(accC4[0].item(), len(C4indices))\n\n", "            # measure elapsed time\n", "            batch_time.update(time.time() - end)\n", "            end = time.time()\n\n", "            #if i % args.print_freq == 0:\n", "            #   progress.print(i)\n\n", "        #print(' * Acc {top1.avg:.3f}'.format(top1=top1))\n", "    return y_pred, y_true, p_pred"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}