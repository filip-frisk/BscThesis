This job can be monitored from: https://scruffy.c3se.chalmers.se/d/alvis-job/alvis-job?var-jobid=60947&from=1617897367000
/tmp/slurmd/job60947/slurm_script: line 10: deactivate: command not found
/tmp/slurmd/job60947/slurm_script: line 17: start: command not found
Starting at Thu Apr  8 17:56:07 CEST 2021
Job Name - EffNet
Running on hosts: alvis2-01
Running on 1 nodes.
Running 1 tasks.
Current working directory is /cephyr/users/filipfri/Alvis/BscProject
10.2
tensor([1.], device='cuda:0')
Using image size:  32
Using filter:  
Training set : 
P19_1_1
P19_1_2
P19_2_1
P19_2_2
P19_3_1
P19_3_2
P20_1_3
P20_1_4
P20_2_2
P20_2_3
P20_2_4
P20_3_1
P20_3_2
P20_3_3
P20_4_1
P20_4_2
P20_4_3
P20_5_1
P20_5_2
P20_6_1
P20_6_2
P20_7_1
P20_7_2
P20_8_1
P20_8_2
P20_9_1
P20_9_2
P9_1_1
P9_2_1
P9_2_2
P9_3_1
P9_3_2
P9_4_1
P9_4_2
Testing set : 
N10_1_1
N10_1_2
N10_1_3
N10_2_1
N10_2_2
P13_1_1
P13_1_2
P13_2_1
P13_2_2
P28_7_5
P28_8_5
P28_10_4
P28_10_5
inflammatory appears 715 times in the non augmented training and validation set
inflammatory appears 6435 times in the augmented training and validation set
lymphocyte appears 1967 times in the non augmented training and validation set
lymphocyte appears 9835 times in the augmented training and validation set
fibroblast and endothelial appears 4228 times in the non augmented training and validation set
fibroblast and endothelial appears 8456 times in the augmented training and validation set
epithelial appears 8706 times in the non augmented training and validation set
epithelial appears 10706 times in the augmented training and validation set
[5148, 7868, 6764, 8565]
train size: 28345
val size: 7087
test size: 11318
Available GPUs: 7
Loaded pretrained weights for efficientnet-b0
=> using pre-trained model 'efficientnet-b0'
[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
Epoch: [0][  0/886]	Time 23.661 (23.661)	Data loading time  4.342 ( 4.342)	Loss 1.4048e+00 (1.4048e+00)	Acc@1  18.75 ( 18.75)
Epoch: [0][110/886]	Time  0.272 ( 0.493)	Data loading time  0.001 ( 0.040)	Loss 1.8231e+00 (1.7008e+00)	Acc@1  25.00 ( 26.94)
Epoch: [0][220/886]	Time  0.313 ( 0.387)	Data loading time  0.000 ( 0.021)	Loss 1.5387e+00 (1.6738e+00)	Acc@1  25.00 ( 26.44)
Epoch: [0][330/886]	Time  0.267 ( 0.351)	Data loading time  0.000 ( 0.014)	Loss 1.5618e+00 (1.6337e+00)	Acc@1  31.25 ( 26.89)
Epoch: [0][440/886]	Time  0.327 ( 0.334)	Data loading time  0.000 ( 0.011)	Loss 1.6436e+00 (1.6204e+00)	Acc@1  18.75 ( 26.81)
Epoch: [0][550/886]	Time  0.271 ( 0.323)	Data loading time  0.001 ( 0.009)	Loss 1.3433e+00 (1.6090e+00)	Acc@1  37.50 ( 26.82)
Epoch: [0][660/886]	Time  0.312 ( 0.316)	Data loading time  0.000 ( 0.007)	Loss 1.4884e+00 (1.5952e+00)	Acc@1  34.38 ( 26.95)
Epoch: [0][770/886]	Time  0.272 ( 0.310)	Data loading time  0.000 ( 0.006)	Loss 1.4283e+00 (1.5803e+00)	Acc@1  46.88 ( 27.10)
Epoch: [0][880/886]	Time  0.323 ( 0.306)	Data loading time  0.002 ( 0.006)	Loss 1.3406e+00 (1.5647e+00)	Acc@1  34.38 ( 27.24)
Traceback (most recent call last):
  File "main.py", line 347, in <module>
    main()
  File "main.py", line 334, in main
    model = run_model(loaders, split_counter, args, class_names,num_item_per_class)
  File "/cephyr/users/filipfri/Alvis/BscProject/run_model.py", line 57, in run_model
    return main_worker(loaders, split, args.gpu, ngpus, args,num_item_per_class)
  File "/cephyr/users/filipfri/Alvis/BscProject/run_model.py", line 167, in main_worker
    train(loaders['train'], model, criterion, optimizer, epoch, args)
  File "/cephyr/users/filipfri/Alvis/BscProject/run_model.py", line 241, in train
    output = model(images)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 161, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 171, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
ValueError: Caught ValueError in replica 6 on device 6.
Original Traceback (most recent call last):
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cephyr/users/filipfri/Alvis/BscProject/EfficientNet_PyTorch/efficientnet_pytorch/model.py", line 193, in forward
    x = self.extract_features(inputs)
  File "/cephyr/users/filipfri/Alvis/BscProject/EfficientNet_PyTorch/efficientnet_pytorch/model.py", line 182, in extract_features
    x = block(x, drop_connect_rate=drop_connect_rate)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cephyr/users/filipfri/Alvis/BscProject/EfficientNet_PyTorch/efficientnet_pytorch/model.py", line 78, in forward
    x = self._swish(self._bn1(self._depthwise_conv(x)))
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 136, in forward
    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/functional.py", line 2054, in batch_norm
    _verify_batch_size(input.size())
  File "/cephyr/users/filipfri/Alvis/clusterEnv/lib/python3.6/site-packages/torch/nn/functional.py", line 2037, in _verify_batch_size
    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 672, 1, 1])

Program finished with exit code 1 at: Thu Apr  8 18:02:02 CEST 2021
Cern here we go
